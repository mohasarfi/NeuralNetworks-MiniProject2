{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import cv2 \n",
        "from PIL import Image\n",
        "from keras import layers,Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,GlobalMaxPool2D,Conv2DTranspose,UpSampling2D\n",
        "from keras.layers import Flatten,Dropout\n",
        "from keras.optimizers import SGD , Adam\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LSTM,SimpleRNN,GRU\n",
        "from keras.layers import TimeDistributed"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pendulum_equation(y0,t,m,l,g):\n",
        "  theta , x = y0\n",
        "  f = [x, -(g/l)*np.sin(theta)]\n",
        "  return f \n",
        "\n",
        "def plot_loss(history,title):\n",
        "  plt.plot(history.history['loss'],label='loss')\n",
        "  plt.plot(history.history['val_loss'],label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Cost')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "  plt.grid()\n",
        "\n",
        "\n",
        "def animationpred(n,nof,model,x_test):\n",
        "  i = 0 \n",
        "  output = []\n",
        "  m = 0\n",
        "  # xtestlist = xtestnew[0]\n",
        "  xtestlist = x_test[0]\n",
        "  xtestlist=xtestlist.reshape(1,10,80,80,3)\n",
        "  plt.imshow(xtestlist[0][-1])\n",
        "  ypred = model.predict(xtestlist)\n",
        "  fig = plt.figure()\n",
        "\n",
        "\n",
        "  while i<=nof :\n",
        "    im = plt.imshow(ypred[0][-1],animated = True)\n",
        "    output.append([im])\n",
        "    xtestlist = np.append(xtestlist[0],np.array([(ypred[0][-1])]),axis=0)\n",
        "    xtestlist = xtestlist.reshape(1,11,80,80,3)\n",
        "    xtestlist = np.delete(xtestlist[0],0,axis=0)\n",
        "    xtestlist = xtestlist.reshape(1,10,80,80,3)\n",
        "    ypred = model.predict(xtestlist)\n",
        "    i += 1 \n",
        "  \n",
        "  ani = animation.ArtistAnimation(fig, output, interval=50, blit=True)\n",
        "  if n == 1 :\n",
        "    ani.save('./Results/RNNFinal/RNNanimation{}.mp4'.format(nof),writer='ffmpeg' ,fps=20)\n",
        "  elif n==2 :\n",
        "    ani.save('./Results/GRUFinal/GRUanimation{}.mp4'.format(nof),writer='ffmpeg' ,fps=20)\n",
        "  elif n==3 : \n",
        "    ani.save('./Results/LSTMFinal/LSTManimation{}.mp4'.format(nof),writer='ffmpeg' ,fps=20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Generating Moving Pendulum animation \n",
        "This animation is generated based on the governing differential equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Kzii0OxJemTT"
      },
      "outputs": [],
      "source": [
        "m = 1 # pendulum mass \n",
        "l = 1 # rod length \n",
        "g = 9.8 \n",
        "y0 = [np.pi/2 , 0.5] # Initial state\n",
        "t = np.linspace(0,6,600)\n",
        "ans = odeint(pendulum_equation,y0,t,args=(m,l,g))\n",
        "\n",
        "fig ,ax = plt.subplots()\n",
        "mylist =[]\n",
        "for i in range(len(ans)):\n",
        "  line, = ax.plot([0,np.sin(ans[i,0])],[0,-np.cos(ans[i,0])],color='black',lw=4 )\n",
        "  ball, = ax.plot(np.sin(ans[i,0]),-np.cos(ans[i,0]),'o',markersize =35,color='blue')\n",
        "  time = ax.text(-0.75,0,\"Time is:\"+\"{:.2f}\".format(t[i]))\n",
        "  mylist.append([line,ball,time])\n",
        "ax.set_aspect('equal','datalim')\n",
        "result = animation.ArtistAnimation(fig,mylist,interval=50)\n",
        "result.save('animation.mp4',writer='ffmpeg' ,fps=20)\n",
        "plt.close(fig) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating training pictures \n",
        "Extract screenshots of the animation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YY2Rf8OtMDrl"
      },
      "outputs": [],
      "source": [
        "myvideo = cv2.VideoCapture(\"./animation.mp4\")\n",
        "framenumber = 0\n",
        "while(True):\n",
        "    cap,frame = myvideo.read()\n",
        "    if cap :\n",
        "        cv2.imwrite('./PendulumData/frame'+str(framenumber)+'.jpg',frame)\n",
        "        framenumber += 1 \n",
        "    else :\n",
        "        break\n",
        "myvideo.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_new shape: (540, 10, 80, 80, 3)\n",
            "y_train_new shape: (540, 1, 80, 80, 3)\n",
            "x_test_new shape: (30, 10, 80, 80, 3)\n",
            "y_test_new shape: (30, 1, 80, 80, 3)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess images\n",
        "def load_and_preprocess_images(path, num_images, size=(80, 80)):\n",
        "    data = []\n",
        "    for i in range(num_images):\n",
        "        image = Image.open(f'{path}/frame{i}.jpg')\n",
        "        image = image.resize(size)\n",
        "        image = np.asarray(image) / 255.0\n",
        "        data.append(image)\n",
        "    return np.array(data)\n",
        "\n",
        "# Prepare training and testing data\n",
        "def prepare_data(data, split_index):\n",
        "    train_data = data[:split_index]\n",
        "    test_data = data[split_index:]\n",
        "\n",
        "    x_train = train_data[:-1]\n",
        "    y_train = train_data[1:]\n",
        "\n",
        "    test_data = test_data[:-8]\n",
        "    x_test = test_data[:-1]\n",
        "    y_test = test_data[1:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "# Reshape data for training, validation, and testing\n",
        "def reshape_data(x_data, y_data, sequence_length):\n",
        "    x_new = []\n",
        "    y_new = []\n",
        "    for i in range(len(x_data) - (sequence_length)):\n",
        "        x_new.append(x_data[i:i + sequence_length])\n",
        "        y_new.append(y_data[i:i + sequence_length][-1])\n",
        "    x_new = np.array(x_new)\n",
        "    y_new = np.array(y_new).reshape((len(x_data) - (sequence_length)),1,*y_data.shape[1:])\n",
        "\n",
        "    return x_new, y_new\n",
        "\n",
        "# Main processing\n",
        "data_path = './PendulumData'\n",
        "num_images = 600\n",
        "split_index = 551\n",
        "sequence_length = 10\n",
        "\n",
        "data = load_and_preprocess_images(data_path, num_images)\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_data(data, split_index)\n",
        "x_train_final, y_train_final = reshape_data(x_train, y_train, sequence_length)\n",
        "x_test_final, y_test_final = reshape_data(x_test, y_test, sequence_length)\n",
        "\n",
        "print(f\"x_train_new shape: {x_train_final.shape}\")\n",
        "print(f\"y_train_new shape: {y_train_final.shape}\")\n",
        "print(f\"x_test_new shape: {x_test_final.shape}\")\n",
        "print(f\"y_test_new shape: {y_test_final.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deep Neural Network Architecture\n",
        "Encoder / LSTM / Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQoJvvl6dbN8"
      },
      "outputs": [],
      "source": [
        "def finalmodel(n,opt,lfunc):\n",
        "  model = Sequential()\n",
        "  ##Encoder Part\n",
        "  model.add(TimeDistributed(Conv2D(27, (3, 3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(10,80,80,3))))\n",
        "  model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(18, (3, 3), activation='relu',kernel_initializer='he_uniform',padding='same')))\n",
        "  model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(9, (3, 3), activation='relu',kernel_initializer='he_uniform',padding='same')))\n",
        "  model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu',kernel_initializer='he_uniform',padding='same')))\n",
        "  model.add(TimeDistributed(Flatten()))\n",
        "  ###\n",
        "  ##LSTM Part\n",
        "  if n == 1 :\n",
        "    model.add((SimpleRNN(500,activation='tanh',kernel_initializer='he_uniform',return_sequences=False)))\n",
        "    model.add(layers.Reshape((1,10,10,5)))\n",
        "  elif n==2 :\n",
        "    model.add((GRU(500,activation='tanh',kernel_initializer='he_uniform',return_sequences=False)))\n",
        "    model.add(layers.Reshape((1,10,10,5)))\n",
        "  elif n==3 : \n",
        "    model.add((LSTM(500,activation='tanh',kernel_initializer='he_uniform',return_sequences=False)))\n",
        "    model.add(layers.Reshape((1,10,10,5)))\n",
        "  ##\n",
        "  ##Decoder part\n",
        "  model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu',kernel_initializer='he_uniform',  padding='same')))\n",
        "  model.add(TimeDistributed(UpSampling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(9, (3, 3), activation='relu',kernel_initializer='he_uniform',  padding='same')))\n",
        "  model.add(TimeDistributed(UpSampling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(18, (3, 3), activation='relu',kernel_initializer='he_uniform',  padding='same')))\n",
        "  model.add(TimeDistributed(UpSampling2D((2,2))))\n",
        "  model.add(TimeDistributed(Conv2D(27, (3, 3), activation='relu',kernel_initializer='he_uniform',  padding='same')))\n",
        "  model.add(TimeDistributed(Conv2D(3, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same')))\n",
        "  model.compile(optimizer = opt , loss = lfunc)\n",
        "  return model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w6eXtneOEBD"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "lstmmodel = finalmodel(3,'adam','mse')\n",
        "lstmhistory = lstmmodel.fit(x_train_final,y_train_final,epochs = 800, batch_size = 10,validation_split = 0.2 ,verbose = None)\n",
        "lstmmodel.summary()\n",
        "lstmmodel.save_weights('./Results/Weights/lstmmodel.h5')\n",
        "# Evaluation\n",
        "lstmmodel.evaluate(x_test_final,y_test_final)\n",
        "# Predicting next N frames\n",
        "noflist = [5,10,20,50,100]\n",
        "for item in noflist:\n",
        "  animationpred(3,item,lstmmodel,x_test_final)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXbNLecEls2b"
      },
      "outputs": [],
      "source": [
        "grumodel = finalmodel(2,'adam','mse')\n",
        "gruhistory = grumodel.fit(x_train_final,y_train_final,epochs = 800, batch_size = 10,validation_split = 0.2 ,verbose = 1)\n",
        "grumodel.summary()\n",
        "grumodel.evaluate(x_test_final,y_test_final)\n",
        "grumodel.save_weights('./Results/Weights/grumodel.h5')\n",
        "for item in noflist:\n",
        "  animationpred(2,item,lstmmodel,x_test_final)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIySp9E7lxEn"
      },
      "outputs": [],
      "source": [
        "rnnmodel = finalmodel(1,'adam','mse')\n",
        "rnnhistory = rnnmodel.fit(x_train_final,y_train_final,epochs = 800, batch_size = 10,validation_split = 0.2 ,verbose = 1)\n",
        "rnnmodel.summary()\n",
        "rnnmodel.evaluate(x_test_final,y_test_final)\n",
        "rnnmodel.save_weights('./Results/Weights/rnnmodel.h5')\n",
        "for item in noflist:\n",
        "  animationpred(1,item,lstmmodel,x_test_final)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bwjIOrynvF__"
      },
      "source": [
        "## Loss function\n",
        "This section studies effect of various loss functions on the performance of DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcj6TkPUvLZh"
      },
      "outputs": [],
      "source": [
        "lossfunctions = ['mae','mse','huber','categorical_crossentropy']\n",
        "for item in lossfunctions:\n",
        "    lossmodel = finalmodel(3,'adam',item)\n",
        "    losshistory = lossmodel.fit(x_train_final,y_train_final,epochs = 800, batch_size = 10,validation_split = 0.2 ,verbose = None)\n",
        "    plot_loss(losshistory,item)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "04k8oMkDf6g2"
      },
      "source": [
        "## Optimizer \n",
        "This section studies effect of various loss functions on the performance of DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jeQSRRmf_1T"
      },
      "outputs": [],
      "source": [
        "Optimizers = [\"RMSProp\"]\n",
        "for item in Optimizers:\n",
        "    optimizermodel = finalmodel(3,item,'mse')\n",
        "    optimizerhistory = lossmodel.fit(x_train_final,y_train_final,epochs = 800, batch_size = 10,validation_split = 0.2 ,verbose = None)\n",
        "    plot_loss(optimizerhistory,item)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bwjIOrynvF__",
        "04k8oMkDf6g2",
        "TqB7mu6RS5li"
      ],
      "name": "Q1MP2Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "1b974d8dc6409b8a7f4985ad95d5f13cda0f74c9c566f9b8689e31408b89a7bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
